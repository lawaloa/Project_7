<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lawal’s Project">
<meta name="dcterms.date" content="2024-11-23">

<title>Project 7 | Modeling Car Insurance Claims Outcome</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#project-overview" id="toc-project-overview" class="nav-link active" data-scroll-target="#project-overview"><span class="header-section-number">1</span> Project Overview</a></li>
  <li><a href="#task" id="toc-task" class="nav-link" data-scroll-target="#task"><span class="header-section-number">2</span> Task</a></li>
  <li><a href="#data-source" id="toc-data-source" class="nav-link" data-scroll-target="#data-source"><span class="header-section-number">3</span> Data Source</a></li>
  <li><a href="#tools" id="toc-tools" class="nav-link" data-scroll-target="#tools"><span class="header-section-number">4</span> Tools</a></li>
  <li><a href="#methodology-stepsexplanations" id="toc-methodology-stepsexplanations" class="nav-link" data-scroll-target="#methodology-stepsexplanations"><span class="header-section-number">5</span> Methodology: Steps/Explanations</a>
  <ul class="collapse">
  <li><a href="#the-necessary-libraries-were-imported-which-include-pandas-and-logit-from-statsmodels.formula.api" id="toc-the-necessary-libraries-were-imported-which-include-pandas-and-logit-from-statsmodels.formula.api" class="nav-link" data-scroll-target="#the-necessary-libraries-were-imported-which-include-pandas-and-logit-from-statsmodels.formula.api"><span class="header-section-number">5.0.1</span> The necessary libraries were imported, which include <code>Pandas</code> and <code>logit</code> from <code>statsmodels.formula.api</code></a></li>
  <li><a href="#reading-in-and-exploring-the-dataset-including-the-imputation-of-missing-values" id="toc-reading-in-and-exploring-the-dataset-including-the-imputation-of-missing-values" class="nav-link" data-scroll-target="#reading-in-and-exploring-the-dataset-including-the-imputation-of-missing-values"><span class="header-section-number">5.0.2</span> Reading in and exploring the dataset, including the imputation of missing values</a></li>
  <li><a href="#finding-the-best-performing-model-with-the-highest-accuracy." id="toc-finding-the-best-performing-model-with-the-highest-accuracy." class="nav-link" data-scroll-target="#finding-the-best-performing-model-with-the-highest-accuracy."><span class="header-section-number">5.0.3</span> Finding the best performing model, with the highest accuracy.</a></li>
  </ul></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis"><span class="header-section-number">6</span> Data Analysis</a></li>
  <li><a href="#resultfindings" id="toc-resultfindings" class="nav-link" data-scroll-target="#resultfindings"><span class="header-section-number">7</span> Result/Findings</a></li>
  <li><a href="#recommendations" id="toc-recommendations" class="nav-link" data-scroll-target="#recommendations"><span class="header-section-number">8</span> Recommendations</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations"><span class="header-section-number">9</span> Limitations</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">10</span> Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">11</span> References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Project 7 | Modeling Car Insurance Claims Outcome</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Lawal’s Project </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Associate Data Science Course in Python by DataCamp Inc
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 23, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="car.jpg" class="img-fluid figure-img"></p>
<figcaption>car</figcaption>
</figure>
</div>
<section id="project-overview" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Project Overview</h1>
<p>Insurance companies invest a lot of <a href="https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf" target="_blank">time and money</a> into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!</p>
<p>Knowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they’ve asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.</p>
<p>They have supplied you with their customer data as a csv file called <code>car_insurance.csv</code>, along with a table detailing the column names and descriptions below.</p>
<div id="tbl-Car" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-Car-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Customer data
</figcaption>
<div aria-describedby="tbl-Car-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="header">
<th>Column</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>id</code></td>
<td>Unique client identifier</td>
</tr>
<tr class="even">
<td><code>age</code></td>
<td>Client’s age: <br> </td>
</tr>
<tr class="odd">
<td><code>gender</code></td>
<td>Client’s gender: <br> </td>
</tr>
<tr class="even">
<td><code>driving_experience</code></td>
<td>Years the client has been driving: <br> </td>
</tr>
<tr class="odd">
<td><code>education</code></td>
<td>Client’s level of education: <br> </td>
</tr>
<tr class="even">
<td><code>income</code></td>
<td>Client’s income level: <br> </td>
</tr>
<tr class="odd">
<td><code>credit_score</code></td>
<td>Client’s credit score (between zero and one)</td>
</tr>
<tr class="even">
<td><code>vehicle_ownership</code></td>
<td>Client’s vehicle ownership status: <br></td>
</tr>
<tr class="odd">
<td><code>vehcile_year</code></td>
<td>Year of vehicle registration: <br></td>
</tr>
<tr class="even">
<td><code>married</code></td>
<td>Client’s marital status: <br></td>
</tr>
<tr class="odd">
<td><code>children</code></td>
<td>Client’s number of children</td>
</tr>
<tr class="even">
<td><code>postal_code</code></td>
<td>Client’s postal code</td>
</tr>
<tr class="odd">
<td><code>annual_mileage</code></td>
<td>Number of miles driven by the client each year</td>
</tr>
<tr class="even">
<td><code>vehicle_type</code></td>
<td>Type of car: <br> </td>
</tr>
<tr class="odd">
<td><code>speeding_violations</code></td>
<td>Total number of speeding violations received by the client</td>
</tr>
<tr class="even">
<td><code>duis</code></td>
<td>Number of times the client has been caught driving under the influence of alcohol</td>
</tr>
<tr class="odd">
<td><code>past_accidents</code></td>
<td>Total number of previous accidents the client has been involved in</td>
</tr>
<tr class="even">
<td><code>outcome</code></td>
<td>Whether the client made a claim on their car insurance (response variable): <br></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="task" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Task</h1>
<ul>
<li><p>Identify the single feature of the data that is the best predictor of whether a customer will put in a claim (the <code>"outcome"</code> column), excluding the <code>"id"</code> column.</p></li>
<li><p>Store as a DataFrame called <code>best_feature_df</code>, containing columns named <code>"best_feature"</code> and <code>"best_accuracy"</code> with the name of the feature with the highest accuracy, and the respective accuracy score.</p></li>
</ul>
</section>
<section id="data-source" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Data Source</h1>
<p>Data: The primary data used for this analysis is the car_insurance.csv, which can be downloaded <a href="https://github.com/lawaloa/Project_7/blob/main/car_insurance.csv" target="_blank">here</a>. See <a href="#tbl-Car" class="quarto-xref">Table&nbsp;1</a> for the column names and descriptions.</p>
</section>
<section id="tools" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Tools</h1>
<p>This project was conducted using <code>JupyterLab</code>, a versatile interactive development environment that facilitates data analysis, visualization, and documentation in Python.</p>
</section>
<section id="methodology-stepsexplanations" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Methodology: Steps/Explanations</h1>
<section id="the-necessary-libraries-were-imported-which-include-pandas-and-logit-from-statsmodels.formula.api" class="level3 unlisted" data-number="5.0.1">
<h3 class="unlisted anchored" data-number="5.0.1" data-anchor-id="the-necessary-libraries-were-imported-which-include-pandas-and-logit-from-statsmodels.formula.api"><span class="header-section-number">5.0.1</span> The necessary libraries were imported, which include <code>Pandas</code> and <code>logit</code> from <code>statsmodels.formula.api</code></h3>
</section>
<section id="reading-in-and-exploring-the-dataset-including-the-imputation-of-missing-values" class="level3 unlisted" data-number="5.0.2">
<h3 class="unlisted anchored" data-number="5.0.2" data-anchor-id="reading-in-and-exploring-the-dataset-including-the-imputation-of-missing-values"><span class="header-section-number">5.0.2</span> Reading in and exploring the dataset, including the imputation of missing values</h3>
<ul>
<li>The Original dataset was loaded, named <code>car</code>.</li>
<li>The first function, <code>explore</code>, was designed to help analyze and clean a dataset by providing a detailed overview of its structure and content, and it also optionally imputes missing values. Here’s a step-by-step explanation:</li>
</ul>
<ol type="1">
<li><strong>Function creation and its arguments</strong>: <code>data</code>, the DataFrame to analyze; <code>head_rows</code>, the number of rows to display from the start of the DataFrame (default: 5); <code>group_by_col</code>, the column used to group data for imputing missing values (default: None); <code>cols_to_impute</code>, the list of columns where missing values will be filled with the group mean (default: None).</li>
</ol>
<p><code>def explore(data, head_rows=5, group_by_col=None, cols_to_impute=None):</code></p>
<ol start="2" type="1">
<li><strong>Function Task 1</strong>: Prints information about the DataFrame, such as:</li>
</ol>
<ul>
<li>Number of rows and columns.</li>
<li>Data types of each column.</li>
<li>Non-null counts for each column.</li>
</ul>
<pre><code>print("\n--- DataFrame Info ---\n")
data.info()</code></pre>
<ol start="3" type="1">
<li><strong>Function Task 2</strong>: Displays summary statistics for all columns, including:</li>
</ol>
<ul>
<li>For numerical data: Mean, standard deviation, min, max, and percentiles.</li>
<li>For categorical data: Frequency counts (mode) and unique counts.</li>
</ul>
<pre><code>print("\n--- Summary Statistics ---\n")
print(data.describe(include='all'))</code></pre>
<ol start="3" type="1">
<li><strong>Function Task 3</strong>: Displays the first head_rows rows (default: 5) of the DataFrame to give a preview of the data.</li>
</ol>
<pre><code>print(f"\n--- First {head_rows} Rows ---\n")
print(data.head(head_rows))</code></pre>
<ol start="4" type="1">
<li><strong>Function Task 4</strong>: Iterates over each column and prints the unique values present in it. Helps understand the distinct data points for each column.</li>
</ol>
<pre><code>print("\n--- Unique Values ---\n")
for col in data.columns:
    print(f"{col}: {data[col].unique()}")</code></pre>
<ol start="5" type="1">
<li><strong>Function Task 5</strong>: Fills missing values (<code>NaN</code>) in the specified columns (<code>cols_to_impute</code>) by grouping data based on <code>group_by_col</code> and calculating the mean for each group.</li>
</ol>
<ul>
<li>Steps:
<ul>
<li>Groups the data by the column specified in <code>group_by_col</code>.</li>
<li>Calculates the mean for the columns listed in <code>cols_to_impute</code> for each group.</li>
<li>Fills missing values in each column by mapping the group means to the corresponding rows.</li>
</ul></li>
<li>Error Handling:
<ul>
<li>Ensures the function doesn’t crash if the specified column is not found or if an error occurs during imputation.</li>
</ul></li>
</ul>
<pre><code>if group_by_col and cols_to_impute:
    print("\n--- Imputing Missing Values ---\n")
    try:
        group_means = data.groupby(group_by_col)[cols_to_impute].mean().to_dict()
        for col in cols_to_impute:
            if col in data.columns:
                print(f"Imputing missing values in '{col}' based on group means of '{group_by_col}'")
                data[col] = data[col].fillna(data[group_by_col].map(group_means[col]))
            else:
                print(f"Column '{col}' not found in the dataset.")
    except Exception as e:
        print(f"Error while imputing missing values: {e}")</code></pre>
<ol start="6" type="1">
<li><strong>Function Task 6</strong>: After the imputation, checks and prints the count of missing values in each column to verify if gaps were successfully filled.</li>
</ol>
<pre><code>print("\n--- Any missing values again ? ---\n")
print(data.isna().sum())</code></pre>
</section>
<section id="finding-the-best-performing-model-with-the-highest-accuracy." class="level3 unlisted" data-number="5.0.3">
<h3 class="unlisted anchored" data-number="5.0.3" data-anchor-id="finding-the-best-performing-model-with-the-highest-accuracy."><span class="header-section-number">5.0.3</span> Finding the best performing model, with the highest accuracy.</h3>
<ul>
<li>The second function, <code>best_logmodel</code>, was designed to identify the single best feature in a dataset for predicting a binary outcome using logistic regression with the statsmodels library. Here’s a detailed explanation:</li>
</ul>
<ol type="1">
<li><strong>Function creation and its arguments</strong>: <code>data</code>, the input dataset for modeling as a pandas DataFrame; <code>outcome_column</code>, the target column (dependent variable) representing the outcome being predicted (default: ‘outcome’); <code>id_column</code>, a unique identifier column to exclude from the analysis (default: ‘id’).</li>
</ol>
<p><code>def best_logmodel(data, outcome_column='outcome', id_column='id'):</code></p>
<ol start="2" type="1">
<li><strong>Function Task</strong>: Creates a new DataFrame (<code>data1</code>) by removing the <code>id_column</code> (not predictive) and the <code>outcome_column</code> (target variable) from the list of features. The remaining columns are treated as potential predictors.</li>
</ol>
<p><code>data1 = data.drop(columns=[id_column, outcome_column])</code></p>
<ol start="3" type="1">
<li><strong>Initialize Tracking Variables</strong>: <code>best_feature</code>, placeholder for the name of the feature with the highest accuracy and <code>best_accuracy</code>, tracks the best accuracy score encountered during the iteration.</li>
</ol>
<pre><code>best_feature = None
best_accuracy = 0</code></pre>
<ol start="4" type="1">
<li><strong>Loop Through Each Feature</strong>: Iterates through all the columns (features) in data1 to evaluate their predictive power for the <code>outcome_column</code>.</li>
</ol>
<p><code>for col in data1.columns:</code></p>
<ol start="5" type="1">
<li><strong>Create the Logistic Regression Formula</strong>: Constructs a formula for logistic regression in the form <code>"outcome_column ~ feature_column"</code>.</li>
</ol>
<p><code>formula = f"{outcome_column} ~ {col}"</code></p>
<ol start="6" type="1">
<li><strong>Fit Logistic Regression Model</strong>: Fits a logistic regression model for the current feature using the <code>logit</code> function from <code>statsmodels</code>. The `disp=False argument suppresses output during model fitting.</li>
</ol>
<p><code>model = logit(formula=formula, data=data).fit(disp=False)</code></p>
<ol start="7" type="1">
<li><strong>Generate Confusion Matrix</strong>: Produces a confusion matrix for the logistic regression model’s predictions.</li>
</ol>
<p><code>confusion_matrix = model.pred_table()</code></p>
<ul>
<li><strong>Confusion Matrix Layout</strong>:</li>
</ul>
<pre><code>[[TN, FP],   # TN = True Negatives, FP = False Positives
 [FN, TP]]   # FN = False Negatives, TP = True Positives</code></pre>
<ol start="8" type="1">
<li><strong>Calculates the model’s accuracy from the confusion matrix</strong>:</li>
</ol>
<ul>
<li><code>TP</code>: True Positives (correctly predicted positives).</li>
<li><code>TN</code>: True Negatives (correctly predicted negatives).</li>
<li><code>T</code>: Total number of predictions.</li>
<li><strong>Accuracy Formula</strong>:</li>
</ul>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total Predictions}}
\]</span></p>
<ol start="9" type="1">
<li><strong>Update the Best Feature</strong>: Compares the current feature’s accuracy with the best accuracy seen so far. If the current feature has a higher accuracy, update <code>best_feature</code> and <code>best_accuracy</code>.</li>
</ol>
<pre><code>if accuracy &gt; best_accuracy:
    best_feature = col
    best_accuracy = accuracy</code></pre>
<ol start="10" type="1">
<li><strong>Store Results in a DataFrame</strong>: Summarizes the results into a pandas DataFrame with:</li>
</ol>
<ul>
<li><code>best_feature</code>: The name of the feature with the highest accuracy.</li>
<li><code>best_accuracy</code>: The corresponding accuracy score.</li>
</ul>
<pre><code>best_feature_df = pd.DataFrame({
    "best_feature": [best_feature],
    "best_accuracy": [best_accuracy]
})</code></pre>
<ol start="11" type="1">
<li><strong>Return the Results</strong>: Returns the DataFrame so that the results can be used or displayed.</li>
</ol>
<p><code>return best_feature_df</code></p>
</section>
</section>
<section id="data-analysis" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Data Analysis</h1>
<div id="d207b291" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required modules</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> logit</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the car_insurance csv file and store as object 'car'</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>car <span class="op">=</span> pd.read_csv(<span class="st">"car_insurance.csv"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Exploring the DataFrame by creating the function 'explore'</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> explore(data, head_rows<span class="op">=</span><span class="dv">5</span>, group_by_col<span class="op">=</span><span class="va">None</span>, cols_to_impute<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Explores the given DataFrame by displaying basic information, summary statistics, </span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    the first few rows, unique values, and imputes missing values with group means if specified.</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): The DataFrame to explore.</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">        head_rows (int): Number of rows to display for the head of the DataFrame. Default is 5.</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">        group_by_col (str): Column name to group by for imputing missing values. Default is None.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">        cols_to_impute (list): List of column names to impute missing values. Default is None.</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- DataFrame Info ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    data.info()</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Summary Statistics ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.describe(include<span class="op">=</span><span class="st">'all'</span>))  <span class="co"># Include all data types in describe()</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- First </span><span class="sc">{</span>head_rows<span class="sc">}</span><span class="ss"> Rows ---</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.head(head_rows))</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Unique Values ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>data[col]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Impute missing values if group_by_col and cols_to_impute are specified</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> group_by_col <span class="kw">and</span> cols_to_impute:</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Imputing Missing Values ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>            group_means <span class="op">=</span> data.groupby(group_by_col)[cols_to_impute].mean().to_dict()  <span class="co"># Group means as a dictionary</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> col <span class="kw">in</span> cols_to_impute:</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f"Imputing missing values in '</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">' based on group means of '</span><span class="sc">{</span>group_by_col<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>                    data[col] <span class="op">=</span> data[col].fillna(data[group_by_col].<span class="bu">map</span>(group_means[col]))</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f"Column '</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">' not found in the dataset."</span>)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Error while imputing missing values: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Any missing values again ? ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.isna().<span class="bu">sum</span>())</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="co"># explore(your_data, group_by_col="outcome", cols_to_impute=["credit_score", "annual_mileage"])</span></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Use 'explore' function to analyze and clean the car dataset by providing a detailed overview of its structure and content, and it also optionally imputes missing values.</span></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>explore(car, group_by_col<span class="op">=</span><span class="st">"outcome"</span>, cols_to_impute<span class="op">=</span>[<span class="st">"credit_score"</span>, <span class="st">"annual_mileage"</span>])</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a function, 'best_logmodel', to identify the single best feature in the dataset for predicting a binary outcome using logistic regression with the statsmodels</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_logmodel(data, outcome_column<span class="op">=</span><span class="st">'outcome'</span>, id_column<span class="op">=</span><span class="st">'id'</span>):</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a><span class="co">    Identifies the single best feature for predicting the outcome column using logistic regression </span></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span class="co">    with statsmodels. Calculates accuracy directly from the confusion matrix.</span></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): The dataset containing features and the outcome column.</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="co">        outcome_column (str): The name of the target column.</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="co">        id_column (str): The name of the column to exclude from analysis.</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame with the best feature and its accuracy score.</span></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Exclude ID and outcome columns from columns set</span></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>    data1 <span class="op">=</span> data.drop(columns<span class="op">=</span>[id_column, outcome_column])</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>    best_feature <span class="op">=</span> <span class="va">None</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>    best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through each columns</span></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> data1.columns:</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create formula for logistic regression</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>        formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>outcome_column<span class="sc">}</span><span class="ss"> ~ </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit logistic regression model on the entire dataset</span></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> logit(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit(disp<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate confusion matrix using pred_table()</span></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>        confusion_matrix <span class="op">=</span> model.pred_table()</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate accuracy from confusion matrix</span></span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>        TP <span class="op">=</span> confusion_matrix[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>        TN <span class="op">=</span> confusion_matrix[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>        T <span class="op">=</span> confusion_matrix.<span class="bu">sum</span>()</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> (TP <span class="op">+</span> TN) <span class="op">/</span> T</span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the best feature if this one is better</span></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> accuracy <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>            best_feature <span class="op">=</span> col</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>            best_accuracy <span class="op">=</span> accuracy</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store results in a DataFrame</span></span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>    best_feature_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_feature"</span>: [best_feature],</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_accuracy"</span>: [best_accuracy]</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_feature_df</span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a><span class="co"># best_feature_df = best_logmodel(your_data)</span></span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a><span class="co"># print(best_feature_df)</span></span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the function, 'best_logmodel', to identify the single best feature in the dataset for predicting a binary outcome using logistic regression with the statsmodels.</span></span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>best_feature_df <span class="op">=</span> best_logmodel(car)</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_feature_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
--- DataFrame Info ---

&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 10000 entries, 0 to 9999
Data columns (total 18 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   id                   10000 non-null  int64  
 1   age                  10000 non-null  int64  
 2   gender               10000 non-null  int64  
 3   driving_experience   10000 non-null  object 
 4   education            10000 non-null  object 
 5   income               10000 non-null  object 
 6   credit_score         9018 non-null   float64
 7   vehicle_ownership    10000 non-null  float64
 8   vehicle_year         10000 non-null  object 
 9   married              10000 non-null  float64
 10  children             10000 non-null  float64
 11  postal_code          10000 non-null  int64  
 12  annual_mileage       9043 non-null   float64
 13  vehicle_type         10000 non-null  object 
 14  speeding_violations  10000 non-null  int64  
 15  duis                 10000 non-null  int64  
 16  past_accidents       10000 non-null  int64  
 17  outcome              10000 non-null  float64
dtypes: float64(6), int64(7), object(5)
memory usage: 1.4+ MB

--- Summary Statistics ---

                   id           age        gender driving_experience  \
count    10000.000000  10000.000000  10000.000000              10000   
unique            NaN           NaN           NaN                  4   
top               NaN           NaN           NaN               0-9y   
freq              NaN           NaN           NaN               3530   
mean    500521.906800      1.489500      0.499000                NaN   
std     290030.768758      1.025278      0.500024                NaN   
min        101.000000      0.000000      0.000000                NaN   
25%     249638.500000      1.000000      0.000000                NaN   
50%     501777.000000      1.000000      0.000000                NaN   
75%     753974.500000      2.000000      1.000000                NaN   
max     999976.000000      3.000000      1.000000                NaN   

          education       income  credit_score  vehicle_ownership  \
count         10000        10000   9018.000000       10000.000000   
unique            3            4           NaN                NaN   
top     high school  upper class           NaN                NaN   
freq           4157         4336           NaN                NaN   
mean            NaN          NaN      0.515813           0.697000   
std             NaN          NaN      0.137688           0.459578   
min             NaN          NaN      0.053358           0.000000   
25%             NaN          NaN      0.417191           0.000000   
50%             NaN          NaN      0.525033           1.000000   
75%             NaN          NaN      0.618312           1.000000   
max             NaN          NaN      0.960819           1.000000   

       vehicle_year       married      children   postal_code  annual_mileage  \
count         10000  10000.000000  10000.000000  10000.000000     9043.000000   
unique            2           NaN           NaN           NaN             NaN   
top     before 2015           NaN           NaN           NaN             NaN   
freq           6967           NaN           NaN           NaN             NaN   
mean            NaN      0.498200      0.688800  19864.548400    11697.003207   
std             NaN      0.500022      0.463008  18915.613855     2818.434528   
min             NaN      0.000000      0.000000  10238.000000     2000.000000   
25%             NaN      0.000000      0.000000  10238.000000    10000.000000   
50%             NaN      0.000000      1.000000  10238.000000    12000.000000   
75%             NaN      1.000000      1.000000  32765.000000    14000.000000   
max             NaN      1.000000      1.000000  92101.000000    22000.000000   

       vehicle_type  speeding_violations         duis  past_accidents  \
count         10000         10000.000000  10000.00000    10000.000000   
unique            2                  NaN          NaN             NaN   
top           sedan                  NaN          NaN             NaN   
freq           9523                  NaN          NaN             NaN   
mean            NaN             1.482900      0.23920        1.056300   
std             NaN             2.241966      0.55499        1.652454   
min             NaN             0.000000      0.00000        0.000000   
25%             NaN             0.000000      0.00000        0.000000   
50%             NaN             0.000000      0.00000        0.000000   
75%             NaN             2.000000      0.00000        2.000000   
max             NaN            22.000000      6.00000       15.000000   

             outcome  
count   10000.000000  
unique           NaN  
top              NaN  
freq             NaN  
mean        0.313300  
std         0.463858  
min         0.000000  
25%         0.000000  
50%         0.000000  
75%         1.000000  
max         1.000000  

--- First 5 Rows ---

       id  age  gender driving_experience    education         income  \
0  569520    3       0               0-9y  high school    upper class   
1  750365    0       1               0-9y         none        poverty   
2  199901    0       0               0-9y  high school  working class   
3  478866    0       1               0-9y   university  working class   
4  731664    1       1             10-19y         none  working class   

   credit_score  vehicle_ownership vehicle_year  married  children  \
0      0.629027                1.0   after 2015      0.0       1.0   
1      0.357757                0.0  before 2015      0.0       0.0   
2      0.493146                1.0  before 2015      0.0       0.0   
3      0.206013                1.0  before 2015      0.0       1.0   
4      0.388366                1.0  before 2015      0.0       0.0   

   postal_code  annual_mileage vehicle_type  speeding_violations  duis  \
0        10238         12000.0        sedan                    0     0   
1        10238         16000.0        sedan                    0     0   
2        10238         11000.0        sedan                    0     0   
3        32765         11000.0        sedan                    0     0   
4        32765         12000.0        sedan                    2     0   

   past_accidents  outcome  
0               0      0.0  
1               0      1.0  
2               0      0.0  
3               0      0.0  
4               1      1.0  

--- Unique Values ---

id: [569520 750365 199901 ... 468409 903459 442696]
age: [3 0 1 2]
gender: [0 1]
driving_experience: ['0-9y' '10-19y' '20-29y' '30y+']
education: ['high school' 'none' 'university']
income: ['upper class' 'poverty' 'working class' 'middle class']
credit_score: [0.62902731 0.35775712 0.49314579 ... 0.47094023 0.36418478 0.43522478]
vehicle_ownership: [1. 0.]
vehicle_year: ['after 2015' 'before 2015']
married: [0. 1.]
children: [1. 0.]
postal_code: [10238 32765 92101 21217]
annual_mileage: [12000. 16000. 11000. 13000. 14000. 10000.  8000.    nan 18000. 17000.
  7000. 15000.  9000.  5000.  6000. 19000.  4000.  3000.  2000. 20000.
 21000. 22000.]
vehicle_type: ['sedan' 'sports car']
speeding_violations: [ 0  2  3  7  6  4 10 13  1  5  9  8 12 11 15 17 19 18 16 14 22]
duis: [0 2 1 3 4 5 6]
past_accidents: [ 0  1  3  7  2  5  4  6  8 10 11  9 12 14 15]
outcome: [0. 1.]

--- Imputing Missing Values ---

Imputing missing values in 'credit_score' based on group means of 'outcome'
Imputing missing values in 'annual_mileage' based on group means of 'outcome'

--- Any missing values again ? ---

id                     0
age                    0
gender                 0
driving_experience     0
education              0
income                 0
credit_score           0
vehicle_ownership      0
vehicle_year           0
married                0
children               0
postal_code            0
annual_mileage         0
vehicle_type           0
speeding_violations    0
duis                   0
past_accidents         0
outcome                0
dtype: int64
         best_feature  best_accuracy
0  driving_experience         0.7771</code></pre>
</div>
</div>
</section>
<section id="resultfindings" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Result/Findings</h1>
<ul>
<li>The analysis identified <code>driving_experience</code> (indicating the years the client has been driving) as the best predictor of whether a customer will file a claim, with an accuracy score of 77.7%. This indicates that the model correctly predicted claims and non-claims in approximately 78 out of 100 cases, making this feature a significant factor in claim prediction.</li>
</ul>
</section>
<section id="recommendations" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Recommendations</h1>
<p>None</p>
</section>
<section id="limitations" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Limitations</h1>
<p>None</p>
</section>
<section id="conclusion" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Conclusion</h1>
<p>My analysis identified <code>driving_experience</code> (years of driving) as the strongest predictor of claim submissions, achieving an accuracy score of 77.7%. This result highlights the importance of driving experience in assessing customer risk. The model correctly classified claims and non-claims in 78 out of 100 cases.</p>
<p>Logistic regression was used to evaluate the predictive power of individual features, and accuracy was calculated using a confusion matrix. The prominence of driving experience suggests that more experienced drivers may exhibit different risk profiles, which could guide targeted policy offerings.</p>
<p>I recommend incorporating this insight into your risk assessment models.</p>
</section>
<section id="references" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> References</h1>
<ol type="1">
<li><p>For loop in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</p></li>
<li><p>Introduction to functions in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</p></li>
<li><p>Introduction to Regression with statsmodels in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Maarten Van den Broeck.</p></li>
<li><p>Exploratory Data Analysis in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</p></li>
<li><p>Python For Data Analysis 3E (Online) by Wes Mckinney Click <a href="https://wesmckinney.com/book/" target="_blank">here</a> to preview.</p></li>
</ol>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Project 7 | Modeling Car Insurance Claims Outcome"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name:  "Lawal's Project"</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: "Associate Data Science Course in Python by DataCamp Inc"</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-11-23"</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="an">highlight-style:</span><span class="co"> pygments</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">    geometry:</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">      - top=30mm</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">      - left=20mm</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">  docx: default</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true   </span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">  eval: true  </span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">  output: true </span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">  error: false   </span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">  cache: false</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co">  include_metadata: false</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="al">![car](car.jpg)</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="fu"># Project Overview</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>Insurance companies invest a lot of <span class="co">[</span><span class="ot">time and money</span><span class="co">](https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf)</span>{target="_blank"} into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>Knowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they've asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>They have supplied you with their customer data as a csv file called <span class="in">`car_insurance.csv`</span>, along with a table detailing the column names and descriptions below.</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>| Column | Description |</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>|--------|-------------|</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>| <span class="in">`id`</span> | Unique client identifier |</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>| <span class="in">`age`</span> | Client's age: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: 16-25&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: 26-39&lt;/li&gt;&lt;li&gt;<span class="in">`2`</span>: 40-64&lt;/li&gt;&lt;li&gt;<span class="in">`3`</span>: 65+&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>| <span class="in">`gender`</span> | Client's gender: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Female&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Male&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>| <span class="in">`driving_experience`</span> | Years the client has been driving: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: 0-9&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: 10-19&lt;/li&gt;&lt;li&gt;<span class="in">`2`</span>: 20-29&lt;/li&gt;&lt;li&gt;<span class="in">`3`</span>: 30+&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>| <span class="in">`education`</span> | Client's level of education: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: No education&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: High school&lt;/li&gt;&lt;li&gt;<span class="in">`2`</span>: University&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>| <span class="in">`income`</span> | Client's income level: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Poverty&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Working class&lt;/li&gt;&lt;li&gt;<span class="in">`2`</span>: Middle class&lt;/li&gt;&lt;li&gt;<span class="in">`3`</span>: Upper class&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>| <span class="in">`credit_score`</span> | Client's credit score (between zero and one) |</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>| <span class="in">`vehicle_ownership`</span> | Client's vehicle ownership status: &lt;br&gt;&lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Does not own their vehilce (paying off finance)&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Owns their vehicle&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>| <span class="in">`vehcile_year`</span> | Year of vehicle registration: &lt;br&gt;&lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Before 2015&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: 2015 or later&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>| <span class="in">`married`</span> | Client's marital status: &lt;br&gt;&lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Not married&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Married&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>| <span class="in">`children`</span> | Client's number of children |</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>| <span class="in">`postal_code`</span> | Client's postal code | </span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>| <span class="in">`annual_mileage`</span> | Number of miles driven by the client each year |</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>| <span class="in">`vehicle_type`</span> | Type of car: &lt;br&gt; &lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: Sedan&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Sports car&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>| <span class="in">`speeding_violations`</span> | Total number of speeding violations received by the client | </span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>| <span class="in">`duis`</span> | Number of times the client has been caught driving under the influence of alcohol |</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>| <span class="in">`past_accidents`</span> | Total number of previous accidents the client has been involved in |</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>| <span class="in">`outcome`</span> | Whether the client made a claim on their car insurance (response variable): &lt;br&gt;&lt;ul&gt;&lt;li&gt;<span class="in">`0`</span>: No claim&lt;/li&gt;&lt;li&gt;<span class="in">`1`</span>: Made a claim&lt;/li&gt;&lt;/ul&gt; |</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>: Customer data {#tbl-Car}</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="fu"># Task</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Identify the single feature of the data that is the best predictor of whether a customer will put in a claim (the <span class="in">`"outcome"`</span> column), excluding the <span class="in">`"id"`</span> column.</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Store as a DataFrame called <span class="in">`best_feature_df`</span>, containing columns named <span class="in">`"best_feature"`</span> and <span class="in">`"best_accuracy"`</span> with the name of the feature with the highest accuracy, and the respective accuracy score.</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data Source</span></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>Data: The primary data used for this analysis is the car_insurance.csv, which can be downloaded <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/lawaloa/Project_7/blob/main/car_insurance.csv)</span>{target="_blank"}. See @tbl-Car for the column names and descriptions.</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a><span class="fu"># Tools</span></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>This project was conducted using <span class="in">`JupyterLab`</span>, a versatile interactive development environment that facilitates data analysis, visualization, and documentation in Python.</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a><span class="fu"># Methodology: Steps/Explanations</span></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a><span class="fu">### The necessary libraries were imported, which include `Pandas` and `logit` from `statsmodels.formula.api` {.unlisted}</span></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reading in and exploring the dataset, including the imputation of missing values {.unlisted}</span></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The Original dataset was loaded, named <span class="in">`car`</span>.</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The first function, <span class="in">`explore`</span>, was designed to help analyze and clean a dataset by providing a detailed overview of its structure and content, and it also optionally imputes missing values. Here's a step-by-step explanation:</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Function creation and its arguments**: <span class="in">`data`</span>, the DataFrame to analyze; <span class="in">`head_rows`</span>, the number of rows to display from the start of the DataFrame (default: 5); <span class="in">`group_by_col`</span>, the column used to group data for imputing missing values (default: None); <span class="in">`cols_to_impute`</span>, the list of columns where missing values will be filled with the group mean (default: None).</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a><span class="in">`def explore(data, head_rows=5, group_by_col=None, cols_to_impute=None):`</span></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Function Task 1**: Prints information about the DataFrame, such as:</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Number of rows and columns.</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data types of each column.</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Non-null counts for each column.</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a><span class="in">print("\n--- DataFrame Info ---\n")</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a><span class="in">data.info()</span></span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Function Task 2**: Displays summary statistics for all columns, including:</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For numerical data: Mean, standard deviation, min, max, and percentiles.</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For categorical data: Frequency counts (mode) and unique counts.</span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a><span class="in">print("\n--- Summary Statistics ---\n")</span></span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a><span class="in">print(data.describe(include='all'))</span></span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>   </span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Function Task 3**: Displays the first head_rows rows (default: 5) of the DataFrame to give a preview of the data.</span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"\n--- First {head_rows} Rows ---\n")</span></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a><span class="in">print(data.head(head_rows))</span></span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Function Task 4**: Iterates over each column and prints the unique values present in it. Helps understand the distinct data points for each column.</span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a><span class="in">print("\n--- Unique Values ---\n")</span></span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a><span class="in">for col in data.columns:</span></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a><span class="in">    print(f"{col}: {data[col].unique()}")</span></span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Function Task 5**: Fills missing values (<span class="in">`NaN`</span>) in the specified columns (<span class="in">`cols_to_impute`</span>) by grouping data based on <span class="in">`group_by_col`</span> and calculating the mean for each group.</span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Steps:</span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Groups the data by the column specified in <span class="in">`group_by_col`</span>.</span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Calculates the mean for the columns listed in <span class="in">`cols_to_impute`</span> for each group.</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Fills missing values in each column by mapping the group means to the corresponding rows.</span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Error Handling:</span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Ensures the function doesn't crash if the specified column is not found or if an error occurs during imputation.</span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a><span class="in">if group_by_col and cols_to_impute:</span></span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a><span class="in">    print("\n--- Imputing Missing Values ---\n")</span></span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a><span class="in">    try:</span></span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a><span class="in">        group_means = data.groupby(group_by_col)[cols_to_impute].mean().to_dict()</span></span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a><span class="in">        for col in cols_to_impute:</span></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a><span class="in">            if col in data.columns:</span></span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a><span class="in">                print(f"Imputing missing values in '{col}' based on group means of '{group_by_col}'")</span></span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a><span class="in">                data[col] = data[col].fillna(data[group_by_col].map(group_means[col]))</span></span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a><span class="in">            else:</span></span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a><span class="in">                print(f"Column '{col}' not found in the dataset.")</span></span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a><span class="in">    except Exception as e:</span></span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a><span class="in">        print(f"Error while imputing missing values: {e}")</span></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Function Task 6**: After the imputation, checks and prints the count of missing values in each column to verify if gaps were successfully filled.</span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a><span class="in">print("\n--- Any missing values again ? ---\n")</span></span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a><span class="in">print(data.isna().sum())</span></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a><span class="fu">### Finding the best performing model, with the highest accuracy. {.unlisted}</span></span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The second function, <span class="in">`best_logmodel`</span>, was designed to identify the single best feature in a dataset for predicting a binary outcome using logistic regression with the statsmodels library. Here's a detailed explanation:</span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-162"><a href="#cb13-162" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Function creation and its arguments**: <span class="in">`data`</span>, the input dataset for modeling as a pandas DataFrame; <span class="in">`outcome_column`</span>, the target column (dependent variable) representing the outcome being predicted (default: 'outcome'); <span class="in">`id_column`</span>, a unique identifier column to exclude from the analysis (default: 'id').</span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a><span class="in">`def best_logmodel(data, outcome_column='outcome', id_column='id'):`</span></span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Function Task**: Creates a new DataFrame (<span class="in">`data1`</span>) by removing the <span class="in">`id_column`</span> (not predictive) and the <span class="in">`outcome_column`</span> (target variable) from the list of features. The remaining columns are treated as potential predictors.</span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a><span class="in">`data1 = data.drop(columns=[id_column, outcome_column])`</span></span>
<span id="cb13-169"><a href="#cb13-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-170"><a href="#cb13-170" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Initialize Tracking Variables**: <span class="in">`best_feature`</span>, placeholder for the name of the feature with the highest accuracy and <span class="in">`best_accuracy`</span>, tracks the best accuracy score encountered during the iteration.</span>
<span id="cb13-171"><a href="#cb13-171" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-172"><a href="#cb13-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a><span class="in">best_feature = None</span></span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a><span class="in">best_accuracy = 0</span></span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-176"><a href="#cb13-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-177"><a href="#cb13-177" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Loop Through Each Feature**: Iterates through all the columns (features) in data1 to evaluate their predictive power for the <span class="in">`outcome_column`</span>.</span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a><span class="in">`for col in data1.columns:`</span></span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Create the Logistic Regression Formula**: Constructs a formula for logistic regression in the form <span class="in">`"outcome_column ~ feature_column"`</span>.</span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-183"><a href="#cb13-183" aria-hidden="true" tabindex="-1"></a><span class="in">`formula = f"{outcome_column} ~ {col}"`</span></span>
<span id="cb13-184"><a href="#cb13-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Fit Logistic Regression Model**:  Fits a logistic regression model for the current feature using the <span class="in">`logit`</span> function from <span class="in">`statsmodels`</span>. The `disp=False argument suppresses output during model fitting.</span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-187"><a href="#cb13-187" aria-hidden="true" tabindex="-1"></a><span class="in">`model = logit(formula=formula, data=data).fit(disp=False)`</span></span>
<span id="cb13-188"><a href="#cb13-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Generate Confusion Matrix**: Produces a confusion matrix for the logistic regression model’s predictions.</span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a><span class="in">`confusion_matrix = model.pred_table()`</span></span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Confusion Matrix Layout**:</span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-196"><a href="#cb13-196" aria-hidden="true" tabindex="-1"></a><span class="in">[[TN, FP],   # TN = True Negatives, FP = False Positives</span></span>
<span id="cb13-197"><a href="#cb13-197" aria-hidden="true" tabindex="-1"></a><span class="in"> [FN, TP]]   # FN = False Negatives, TP = True Positives</span></span>
<span id="cb13-198"><a href="#cb13-198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-199"><a href="#cb13-199" aria-hidden="true" tabindex="-1"></a><span class="ss">8. </span>**Calculates the model’s accuracy from the confusion matrix**:</span>
<span id="cb13-200"><a href="#cb13-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-201"><a href="#cb13-201" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`TP`</span>: True Positives (correctly predicted positives).</span>
<span id="cb13-202"><a href="#cb13-202" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`TN`</span>: True Negatives (correctly predicted negatives).</span>
<span id="cb13-203"><a href="#cb13-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`T`</span>: Total number of predictions.</span>
<span id="cb13-204"><a href="#cb13-204" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Accuracy Formula**: </span>
<span id="cb13-205"><a href="#cb13-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-206"><a href="#cb13-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-207"><a href="#cb13-207" aria-hidden="true" tabindex="-1"></a>\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total Predictions}}</span>
<span id="cb13-208"><a href="#cb13-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-209"><a href="#cb13-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-210"><a href="#cb13-210" aria-hidden="true" tabindex="-1"></a><span class="ss">9. </span>**Update the Best Feature**: Compares the current feature’s accuracy with the best accuracy seen so far. If the current feature has a higher accuracy, update <span class="in">`best_feature`</span> and <span class="in">`best_accuracy`</span>.</span>
<span id="cb13-211"><a href="#cb13-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-212"><a href="#cb13-212" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-213"><a href="#cb13-213" aria-hidden="true" tabindex="-1"></a><span class="in">if accuracy &gt; best_accuracy:</span></span>
<span id="cb13-214"><a href="#cb13-214" aria-hidden="true" tabindex="-1"></a><span class="in">    best_feature = col</span></span>
<span id="cb13-215"><a href="#cb13-215" aria-hidden="true" tabindex="-1"></a><span class="in">    best_accuracy = accuracy</span></span>
<span id="cb13-216"><a href="#cb13-216" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb13-217"><a href="#cb13-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-218"><a href="#cb13-218" aria-hidden="true" tabindex="-1"></a><span class="ss">10. </span>**Store Results in a DataFrame**: Summarizes the results into a pandas DataFrame with:</span>
<span id="cb13-219"><a href="#cb13-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-220"><a href="#cb13-220" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`best_feature`</span>: The name of the feature with the highest accuracy.</span>
<span id="cb13-221"><a href="#cb13-221" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`best_accuracy`</span>: The corresponding accuracy score.</span>
<span id="cb13-222"><a href="#cb13-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-223"><a href="#cb13-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-224"><a href="#cb13-224" aria-hidden="true" tabindex="-1"></a><span class="in">best_feature_df = pd.DataFrame({</span></span>
<span id="cb13-225"><a href="#cb13-225" aria-hidden="true" tabindex="-1"></a><span class="in">    "best_feature": [best_feature],</span></span>
<span id="cb13-226"><a href="#cb13-226" aria-hidden="true" tabindex="-1"></a><span class="in">    "best_accuracy": [best_accuracy]</span></span>
<span id="cb13-227"><a href="#cb13-227" aria-hidden="true" tabindex="-1"></a><span class="in">})</span></span>
<span id="cb13-228"><a href="#cb13-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-229"><a href="#cb13-229" aria-hidden="true" tabindex="-1"></a><span class="ss">11. </span>**Return the Results**: Returns the DataFrame so that the results can be used or displayed.</span>
<span id="cb13-230"><a href="#cb13-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-231"><a href="#cb13-231" aria-hidden="true" tabindex="-1"></a><span class="in">`return best_feature_df`</span></span>
<span id="cb13-232"><a href="#cb13-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-233"><a href="#cb13-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-234"><a href="#cb13-234" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data Analysis</span></span>
<span id="cb13-235"><a href="#cb13-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-238"><a href="#cb13-238" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-239"><a href="#cb13-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required modules</span></span>
<span id="cb13-240"><a href="#cb13-240" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-241"><a href="#cb13-241" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> logit</span>
<span id="cb13-242"><a href="#cb13-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-243"><a href="#cb13-243" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the car_insurance csv file and store as object 'car'</span></span>
<span id="cb13-244"><a href="#cb13-244" aria-hidden="true" tabindex="-1"></a>car <span class="op">=</span> pd.read_csv(<span class="st">"car_insurance.csv"</span>)</span>
<span id="cb13-245"><a href="#cb13-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-246"><a href="#cb13-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Exploring the DataFrame by creating the function 'explore'</span></span>
<span id="cb13-247"><a href="#cb13-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-248"><a href="#cb13-248" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> explore(data, head_rows<span class="op">=</span><span class="dv">5</span>, group_by_col<span class="op">=</span><span class="va">None</span>, cols_to_impute<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb13-249"><a href="#cb13-249" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-250"><a href="#cb13-250" aria-hidden="true" tabindex="-1"></a><span class="co">    Explores the given DataFrame by displaying basic information, summary statistics, </span></span>
<span id="cb13-251"><a href="#cb13-251" aria-hidden="true" tabindex="-1"></a><span class="co">    the first few rows, unique values, and imputes missing values with group means if specified.</span></span>
<span id="cb13-252"><a href="#cb13-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-253"><a href="#cb13-253" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb13-254"><a href="#cb13-254" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): The DataFrame to explore.</span></span>
<span id="cb13-255"><a href="#cb13-255" aria-hidden="true" tabindex="-1"></a><span class="co">        head_rows (int): Number of rows to display for the head of the DataFrame. Default is 5.</span></span>
<span id="cb13-256"><a href="#cb13-256" aria-hidden="true" tabindex="-1"></a><span class="co">        group_by_col (str): Column name to group by for imputing missing values. Default is None.</span></span>
<span id="cb13-257"><a href="#cb13-257" aria-hidden="true" tabindex="-1"></a><span class="co">        cols_to_impute (list): List of column names to impute missing values. Default is None.</span></span>
<span id="cb13-258"><a href="#cb13-258" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-259"><a href="#cb13-259" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- DataFrame Info ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-260"><a href="#cb13-260" aria-hidden="true" tabindex="-1"></a>    data.info()</span>
<span id="cb13-261"><a href="#cb13-261" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-262"><a href="#cb13-262" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Summary Statistics ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-263"><a href="#cb13-263" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.describe(include<span class="op">=</span><span class="st">'all'</span>))  <span class="co"># Include all data types in describe()</span></span>
<span id="cb13-264"><a href="#cb13-264" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-265"><a href="#cb13-265" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- First </span><span class="sc">{</span>head_rows<span class="sc">}</span><span class="ss"> Rows ---</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb13-266"><a href="#cb13-266" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.head(head_rows))</span>
<span id="cb13-267"><a href="#cb13-267" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-268"><a href="#cb13-268" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Unique Values ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-269"><a href="#cb13-269" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb13-270"><a href="#cb13-270" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>data[col]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-271"><a href="#cb13-271" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-272"><a href="#cb13-272" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Impute missing values if group_by_col and cols_to_impute are specified</span></span>
<span id="cb13-273"><a href="#cb13-273" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> group_by_col <span class="kw">and</span> cols_to_impute:</span>
<span id="cb13-274"><a href="#cb13-274" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Imputing Missing Values ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-275"><a href="#cb13-275" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb13-276"><a href="#cb13-276" aria-hidden="true" tabindex="-1"></a>            group_means <span class="op">=</span> data.groupby(group_by_col)[cols_to_impute].mean().to_dict()  <span class="co"># Group means as a dictionary</span></span>
<span id="cb13-277"><a href="#cb13-277" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> col <span class="kw">in</span> cols_to_impute:</span>
<span id="cb13-278"><a href="#cb13-278" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb13-279"><a href="#cb13-279" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f"Imputing missing values in '</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">' based on group means of '</span><span class="sc">{</span>group_by_col<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb13-280"><a href="#cb13-280" aria-hidden="true" tabindex="-1"></a>                    data[col] <span class="op">=</span> data[col].fillna(data[group_by_col].<span class="bu">map</span>(group_means[col]))</span>
<span id="cb13-281"><a href="#cb13-281" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb13-282"><a href="#cb13-282" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f"Column '</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">' not found in the dataset."</span>)</span>
<span id="cb13-283"><a href="#cb13-283" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb13-284"><a href="#cb13-284" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Error while imputing missing values: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-285"><a href="#cb13-285" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-286"><a href="#cb13-286" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Any missing values again ? ---</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-287"><a href="#cb13-287" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.isna().<span class="bu">sum</span>())</span>
<span id="cb13-288"><a href="#cb13-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-289"><a href="#cb13-289" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb13-290"><a href="#cb13-290" aria-hidden="true" tabindex="-1"></a><span class="co"># explore(your_data, group_by_col="outcome", cols_to_impute=["credit_score", "annual_mileage"])</span></span>
<span id="cb13-291"><a href="#cb13-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-292"><a href="#cb13-292" aria-hidden="true" tabindex="-1"></a><span class="co"># Use 'explore' function to analyze and clean the car dataset by providing a detailed overview of its structure and content, and it also optionally imputes missing values.</span></span>
<span id="cb13-293"><a href="#cb13-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-294"><a href="#cb13-294" aria-hidden="true" tabindex="-1"></a>explore(car, group_by_col<span class="op">=</span><span class="st">"outcome"</span>, cols_to_impute<span class="op">=</span>[<span class="st">"credit_score"</span>, <span class="st">"annual_mileage"</span>])</span>
<span id="cb13-295"><a href="#cb13-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-296"><a href="#cb13-296" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a function, 'best_logmodel', to identify the single best feature in the dataset for predicting a binary outcome using logistic regression with the statsmodels</span></span>
<span id="cb13-297"><a href="#cb13-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-298"><a href="#cb13-298" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_logmodel(data, outcome_column<span class="op">=</span><span class="st">'outcome'</span>, id_column<span class="op">=</span><span class="st">'id'</span>):</span>
<span id="cb13-299"><a href="#cb13-299" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-300"><a href="#cb13-300" aria-hidden="true" tabindex="-1"></a><span class="co">    Identifies the single best feature for predicting the outcome column using logistic regression </span></span>
<span id="cb13-301"><a href="#cb13-301" aria-hidden="true" tabindex="-1"></a><span class="co">    with statsmodels. Calculates accuracy directly from the confusion matrix.</span></span>
<span id="cb13-302"><a href="#cb13-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-303"><a href="#cb13-303" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb13-304"><a href="#cb13-304" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): The dataset containing features and the outcome column.</span></span>
<span id="cb13-305"><a href="#cb13-305" aria-hidden="true" tabindex="-1"></a><span class="co">        outcome_column (str): The name of the target column.</span></span>
<span id="cb13-306"><a href="#cb13-306" aria-hidden="true" tabindex="-1"></a><span class="co">        id_column (str): The name of the column to exclude from analysis.</span></span>
<span id="cb13-307"><a href="#cb13-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-308"><a href="#cb13-308" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-309"><a href="#cb13-309" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame with the best feature and its accuracy score.</span></span>
<span id="cb13-310"><a href="#cb13-310" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-311"><a href="#cb13-311" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Exclude ID and outcome columns from columns set</span></span>
<span id="cb13-312"><a href="#cb13-312" aria-hidden="true" tabindex="-1"></a>    data1 <span class="op">=</span> data.drop(columns<span class="op">=</span>[id_column, outcome_column])</span>
<span id="cb13-313"><a href="#cb13-313" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-314"><a href="#cb13-314" aria-hidden="true" tabindex="-1"></a>    best_feature <span class="op">=</span> <span class="va">None</span></span>
<span id="cb13-315"><a href="#cb13-315" aria-hidden="true" tabindex="-1"></a>    best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-316"><a href="#cb13-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-317"><a href="#cb13-317" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through each columns</span></span>
<span id="cb13-318"><a href="#cb13-318" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> data1.columns:</span>
<span id="cb13-319"><a href="#cb13-319" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create formula for logistic regression</span></span>
<span id="cb13-320"><a href="#cb13-320" aria-hidden="true" tabindex="-1"></a>        formula <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>outcome_column<span class="sc">}</span><span class="ss"> ~ </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb13-321"><a href="#cb13-321" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-322"><a href="#cb13-322" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit logistic regression model on the entire dataset</span></span>
<span id="cb13-323"><a href="#cb13-323" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> logit(formula<span class="op">=</span>formula, data<span class="op">=</span>data).fit(disp<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-324"><a href="#cb13-324" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-325"><a href="#cb13-325" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate confusion matrix using pred_table()</span></span>
<span id="cb13-326"><a href="#cb13-326" aria-hidden="true" tabindex="-1"></a>        confusion_matrix <span class="op">=</span> model.pred_table()</span>
<span id="cb13-327"><a href="#cb13-327" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-328"><a href="#cb13-328" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate accuracy from confusion matrix</span></span>
<span id="cb13-329"><a href="#cb13-329" aria-hidden="true" tabindex="-1"></a>        TP <span class="op">=</span> confusion_matrix[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb13-330"><a href="#cb13-330" aria-hidden="true" tabindex="-1"></a>        TN <span class="op">=</span> confusion_matrix[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb13-331"><a href="#cb13-331" aria-hidden="true" tabindex="-1"></a>        T <span class="op">=</span> confusion_matrix.<span class="bu">sum</span>()</span>
<span id="cb13-332"><a href="#cb13-332" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> (TP <span class="op">+</span> TN) <span class="op">/</span> T</span>
<span id="cb13-333"><a href="#cb13-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-334"><a href="#cb13-334" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the best feature if this one is better</span></span>
<span id="cb13-335"><a href="#cb13-335" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> accuracy <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb13-336"><a href="#cb13-336" aria-hidden="true" tabindex="-1"></a>            best_feature <span class="op">=</span> col</span>
<span id="cb13-337"><a href="#cb13-337" aria-hidden="true" tabindex="-1"></a>            best_accuracy <span class="op">=</span> accuracy</span>
<span id="cb13-338"><a href="#cb13-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-339"><a href="#cb13-339" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store results in a DataFrame</span></span>
<span id="cb13-340"><a href="#cb13-340" aria-hidden="true" tabindex="-1"></a>    best_feature_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-341"><a href="#cb13-341" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_feature"</span>: [best_feature],</span>
<span id="cb13-342"><a href="#cb13-342" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_accuracy"</span>: [best_accuracy]</span>
<span id="cb13-343"><a href="#cb13-343" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb13-344"><a href="#cb13-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-345"><a href="#cb13-345" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_feature_df</span>
<span id="cb13-346"><a href="#cb13-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-347"><a href="#cb13-347" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb13-348"><a href="#cb13-348" aria-hidden="true" tabindex="-1"></a><span class="co"># best_feature_df = best_logmodel(your_data)</span></span>
<span id="cb13-349"><a href="#cb13-349" aria-hidden="true" tabindex="-1"></a><span class="co"># print(best_feature_df)</span></span>
<span id="cb13-350"><a href="#cb13-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-351"><a href="#cb13-351" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the function, 'best_logmodel', to identify the single best feature in the dataset for predicting a binary outcome using logistic regression with the statsmodels.</span></span>
<span id="cb13-352"><a href="#cb13-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-353"><a href="#cb13-353" aria-hidden="true" tabindex="-1"></a>best_feature_df <span class="op">=</span> best_logmodel(car)</span>
<span id="cb13-354"><a href="#cb13-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-355"><a href="#cb13-355" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_feature_df)</span>
<span id="cb13-356"><a href="#cb13-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-357"><a href="#cb13-357" aria-hidden="true" tabindex="-1"></a><span class="fu"># Result/Findings</span></span>
<span id="cb13-358"><a href="#cb13-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-359"><a href="#cb13-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The analysis identified <span class="in">`driving_experience`</span> (indicating the years the client has been driving) as the best predictor of whether a customer will file a claim, with an accuracy score of 77.7%. This indicates that the model correctly predicted claims and non-claims in approximately 78 out of 100 cases, making this feature a significant factor in claim prediction.</span>
<span id="cb13-360"><a href="#cb13-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-361"><a href="#cb13-361" aria-hidden="true" tabindex="-1"></a><span class="fu"># Recommendations</span></span>
<span id="cb13-362"><a href="#cb13-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-363"><a href="#cb13-363" aria-hidden="true" tabindex="-1"></a>None</span>
<span id="cb13-364"><a href="#cb13-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-365"><a href="#cb13-365" aria-hidden="true" tabindex="-1"></a><span class="fu"># Limitations</span></span>
<span id="cb13-366"><a href="#cb13-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-367"><a href="#cb13-367" aria-hidden="true" tabindex="-1"></a>None</span>
<span id="cb13-368"><a href="#cb13-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-369"><a href="#cb13-369" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb13-370"><a href="#cb13-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-371"><a href="#cb13-371" aria-hidden="true" tabindex="-1"></a>My analysis identified <span class="in">`driving_experience`</span> (years of driving) as the strongest predictor of claim submissions, achieving an accuracy score of 77.7%. This result highlights the importance of driving experience in assessing customer risk. The model correctly classified claims and non-claims in 78 out of 100 cases.</span>
<span id="cb13-372"><a href="#cb13-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-373"><a href="#cb13-373" aria-hidden="true" tabindex="-1"></a>Logistic regression was used to evaluate the predictive power of individual features, and accuracy was calculated using a confusion matrix. The prominence of driving experience suggests that more experienced drivers may exhibit different risk profiles, which could guide targeted policy offerings.</span>
<span id="cb13-374"><a href="#cb13-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-375"><a href="#cb13-375" aria-hidden="true" tabindex="-1"></a>I recommend incorporating this insight into your risk assessment models.</span>
<span id="cb13-376"><a href="#cb13-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-377"><a href="#cb13-377" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span>
<span id="cb13-378"><a href="#cb13-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-379"><a href="#cb13-379" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>For loop in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</span>
<span id="cb13-380"><a href="#cb13-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-381"><a href="#cb13-381" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Introduction to functions in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</span>
<span id="cb13-382"><a href="#cb13-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-383"><a href="#cb13-383" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Introduction to Regression with statsmodels in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Maarten Van den Broeck.</span>
<span id="cb13-384"><a href="#cb13-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-385"><a href="#cb13-385" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Exploratory Data Analysis in Python in Intermediate Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by Hugo Bowne-Henderson.</span>
<span id="cb13-386"><a href="#cb13-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-387"><a href="#cb13-387" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Python For Data Analysis 3E (Online) by Wes Mckinney Click <span class="co">[</span><span class="ot">here</span><span class="co">](https://wesmckinney.com/book/)</span>{target="_blank"} to preview.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>